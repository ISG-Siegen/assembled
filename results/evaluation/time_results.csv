file,real_time,user_time,sys_time,note,sequential
example_crawler_cc18.py,"55m27,954s","17m14,925s","0m30,938s","OpenML Cache was cleared before execution.",1
benchmark_set_search.py,"6m50,238s","6m33,709s","0m21,767s","-",1
example_run_benchmark.py,"256m2,796s","271m9,808s","30m5,162s","-",1
runtime_test.py,"37m0,4631298383077s","-","-","Measured with Python's Time Module (see the file itself). Otherwise, the time would have included loading the model and dataset from OpenML (which we deemed unfair). OpenML's code to run the model on the task is sequential by default in newer version. For older versions, we think it runs in parallel by default (we have not found the documentation for OpenML version 0.9 that we had to use for this time measurement). We observed that all our 64 cores were active during the evaluation and that the CPU time was much higher than the real time. We think that some part of the training or evaluation did in fact use n_job=-1. However, as fixing this would only increase the runtime and thus make our results look even better, we decided against changing the OpenML default code of Version 0.9 as seen in the python script. The required changes might appear malicious otherwise.",0
